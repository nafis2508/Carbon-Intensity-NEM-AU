{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be5810e-8018-4740-bce6-23ffbfeeb706",
   "metadata": {},
   "source": [
    "# Question 2 - \"What is the shape of the intra-daily carbon emission intensity curve for the NEM and for the five regional markets. What can be concluded about trends in this pattern? Considering the typical consumption pattern of a household or company, which of them is more likely to have a lower emission intensity per KWh of electricity consumption.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211efd23-c714-4cb9-8acc-2b07d0008a19",
   "metadata": {},
   "source": [
    "### üì¶ Environment Setup: Installing Required Libraries\n",
    "\n",
    "Before fetching and analyzing emissions data, we need to ensure that all required libraries are installed. These libraries allow us to authenticate securely with the CSIRO API, retrieve the emissions data, and handle large datasets efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383178d0-e4a2-4b95-a1ba-2049ea13efd7",
   "metadata": {},
   "source": [
    "###  Install Required Packages\n",
    "\n",
    "To begin the analysis, we need to install the following Python packages:\n",
    "\n",
    "- `requests`: For making HTTP requests to the CSIRO API.\n",
    "- `requests-oauth2client`: For handling OAuth2 authentication.\n",
    "- `polars`: A high-performance DataFrame library used to parse and save large datasets.\n",
    "\n",
    "These packages allow us to authenticate, download, and process emissions data efficiently from the CSIRO Senaps platform.\n",
    "\n",
    "Run the following cell to ensure all dependencies are installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4af0232b-ff37-4e6e-9a7a-248e84e57413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: requests-oauth2client in /opt/anaconda3/lib/python3.12/site-packages (1.7.0)\n",
      "Requirement already satisfied: polars in /opt/anaconda3/lib/python3.12/site-packages (1.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from requests-oauth2client) (25.3.0)\n",
      "Requirement already satisfied: binapy>=0.8 in /opt/anaconda3/lib/python3.12/site-packages (from requests-oauth2client) (0.8.0)\n",
      "Requirement already satisfied: furl>=2.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from requests-oauth2client) (2.1.4)\n",
      "Requirement already satisfied: jwskate>=0.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests-oauth2client) (0.12.2)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from binapy>=0.8->requests-oauth2client) (4.11.0)\n",
      "Requirement already satisfied: six>=1.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from furl>=2.1.2->requests-oauth2client) (1.16.0)\n",
      "Requirement already satisfied: orderedmultidict>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from furl>=2.1.2->requests-oauth2client) (1.0.1)\n",
      "Requirement already satisfied: cryptography>=3.4 in /opt/anaconda3/lib/python3.12/site-packages (from jwskate>=0.11.1->requests-oauth2client) (43.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography>=3.4->jwskate>=0.11.1->requests-oauth2client) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=3.4->jwskate>=0.11.1->requests-oauth2client) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests requests-oauth2client polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b7483-eb44-49f0-9a80-2321511b2853",
   "metadata": {},
   "source": [
    "### üìä Justification for Dataset and Timeframe Selection\n",
    "\n",
    "To analyze the **intra-daily carbon emission intensity patterns** for the NEM and its five regional markets (NSW, QLD, VIC, SA, TAS), I selected the **CSIRO regional emissions dataset** because:\n",
    "\n",
    "- ‚úÖ **High Temporal Resolution**: It provides 5-minute interval emissions data, enabling a detailed intra-day analysis.\n",
    "- ‚úÖ **Regional Breakdown**: Each state is recorded individually, aligning perfectly with the need to compare all five regional markets.\n",
    "- ‚úÖ **Official & Reliable**: Data is sourced via the Eratos platform from CSIRO, ensuring credibility and consistency.\n",
    "\n",
    "### ‚è≥ Why 2019 to April 2025?\n",
    "\n",
    "- üîÑ **Captures Seasonal and Policy Variations**: A 5+ year span helps smooth out short-term fluctuations and includes key changes in grid mix and renewable uptake.\n",
    "- üåê **COVID-19 and Post-pandemic Trends**: The timeframe includes pre-COVID, lockdown, and recovery periods, offering valuable insight into behavioral shifts.\n",
    "- üìà **Improves Trend Analysis**: Extending beyond a single year avoids overfitting conclusions to temporary anomalies or weather effects.\n",
    "- üßÆ **Enables Better User-Type Comparison**: The broader the data, the more representative it becomes for distinguishing between household and company emission intensity patterns across different hours.\n",
    "\n",
    "This dataset and timeframe offer the granularity and context necessary to draw meaningful conclusions about daily carbon intensity patterns and their implications for household vs company energy consumption behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba2a4e-82d9-42b2-b2ff-816112f649d5",
   "metadata": {},
   "source": [
    "### üì• Download Emissions Data (2019‚ÄìApr 2025)\n",
    "\n",
    "Extract and save 5-minute interval carbon emission data for all NEM regions using the CSIRO API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c4b5bd-bf3a-460b-8927-ef2e30de5ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSIRO data from 2019 to April 2025 downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import polars as pl\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "from pathlib import Path\n",
    "from requests_oauth2client import OAuth2Client, OAuth2ClientCredentialsAuth\n",
    "from typing import List\n",
    "\n",
    "# ‚úÖ Your new credentials\n",
    "CLIENT_ID = \"5259460c-3aa8-421a-afc2-eefca36ab37e\"\n",
    "CLIENT_SECRET = \"~2s8Q~9b~pQ458c140PcH5mJFgKsspfW_6upCdAE\"\n",
    "\n",
    "class MyEmissionsData(requests.Session):\n",
    "    _auth_url = \"https://login.microsoftonline.com/a815c246-a01f-4d10-bc3e-eeb6a48ef48a/oauth2/v2.0/token\"\n",
    "    _senaps_url = \"https://senaps.eratos.com/api/sensor/v2/observations\"\n",
    "\n",
    "    def __init__(self, client_id: str = CLIENT_ID, client_secret: str = CLIENT_SECRET):\n",
    "        super().__init__()\n",
    "        oauth2client = OAuth2Client(self._auth_url, (client_id, client_secret))\n",
    "        self.auth = OAuth2ClientCredentialsAuth(oauth2client, scope=f\"{client_id}/.default\")\n",
    "        self.headers = {\n",
    "            \"accept\": \"*/*\",\n",
    "            \"content-type\": \"application/json\",\n",
    "        }\n",
    "\n",
    "    def download_and_parse_data(self, *, write_path: Path, regions: List[str], start: str, end: str, limit: int = 99_999_999):\n",
    "        if not regions:\n",
    "            raise ValueError(\"`regions` list cannot be empty\")\n",
    "        parser = self._parse_single_stream if len(regions) == 1 else self._parse_multiple_streams\n",
    "\n",
    "        streamid = \",\".join(\n",
    "            f\"csiro.energy.dch.agshop.regional_global_emissions.{region}\" for region in regions\n",
    "        )\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            fname = Path(tmpdir) / \"response.json\"\n",
    "            with self.get(\n",
    "                url=self._senaps_url,\n",
    "                params=dict(streamid=streamid, start=start, end=end, limit=limit),\n",
    "            ) as response:\n",
    "                response.raise_for_status()\n",
    "                with open(fname, \"wb\") as fp:\n",
    "                    for chunk in response.iter_content(chunk_size=1024):\n",
    "                        fp.write(chunk)\n",
    "\n",
    "            write_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            with open(fname, \"r\") as fp:\n",
    "                data = json.load(fp)\n",
    "                parser(data, write_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_single_stream(data, write_path):\n",
    "        col_name = data[\"_embedded\"][\"stream\"][\"_links\"][\"self\"][\"id\"]\n",
    "        (\n",
    "            pl.LazyFrame([\n",
    "                {\"timestamp\": elem[\"t\"], col_name: elem[\"v\"][\"v\"]}\n",
    "                for elem in data[\"results\"]\n",
    "            ])\n",
    "            .with_columns(\n",
    "                pl.col(\"timestamp\")\n",
    "                .str.strptime(pl.Datetime, format=\"%Y-%m-%dT%H:%M:%S%.fZ\", strict=True)\n",
    "                .cast(pl.Datetime(time_unit=\"ms\", time_zone=\"UTC\"))\n",
    "            )\n",
    "            .sort(\"timestamp\")\n",
    "            .sink_parquet(write_path)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_multiple_streams(data, write_path):\n",
    "        (\n",
    "            pl.LazyFrame([\n",
    "                {\n",
    "                    \"timestamp\": key,\n",
    "                    \"struct\": {k: v[\"v\"] for k, v in val.items()}\n",
    "                }\n",
    "                for elem in data[\"results\"]\n",
    "                for key, val in elem.items()\n",
    "            ])\n",
    "            .unnest(\"struct\")\n",
    "            .with_columns(\n",
    "                pl.col(\"timestamp\")\n",
    "                .str.strptime(pl.Datetime, format=\"%Y-%m-%dT%H:%M:%S%.fZ\", strict=True)\n",
    "                .cast(pl.Datetime(time_unit=\"ms\", time_zone=\"UTC\"))\n",
    "            )\n",
    "            .sort(\"timestamp\")\n",
    "            .sink_parquet(write_path)\n",
    "        )\n",
    "\n",
    "# ‚úÖ Download data from 2019 to April 2025\n",
    "if __name__ == \"__main__\":\n",
    "    e = MyEmissionsData()\n",
    "    e.download_and_parse_data(\n",
    "        regions=[\"nsw\", \"qld\", \"vic\", \"sa\", \"tas\"],\n",
    "        start=\"2019-01-01T00:00:00.000Z\",\n",
    "        end=\"2025-04-30T23:59:59.999Z\",\n",
    "        write_path=Path.home() / \"Desktop\" / \"dataset_merge\" / \"Question 2\" / \"csiro_2019_to_2025.parquet\"\n",
    "    )\n",
    "    print(\"‚úÖ CSIRO data from 2019 to April 2025 downloaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1563d643-5035-4e3c-aeeb-f93fd2197b86",
   "metadata": {},
   "source": [
    "### üîÑ Converting Parquet to CSV\n",
    "\n",
    "While `.parquet` files are optimized for storage and speed‚Äîespecially in big data environments‚Äî`.csv` files offer greater **readability and compatibility** with traditional data analysis tools such as Excel, pandas, and Streamlit. \n",
    "\n",
    "For the purpose of this project:\n",
    "- üîç I may need to visually inspect and quickly browse data samples.\n",
    "- üìä Some visualization libraries or dashboards (e.g., Streamlit or web tools) integrate more smoothly with `.csv` inputs.\n",
    "- ü§ù Easier sharing with collaborators who may not be familiar with `.parquet`.\n",
    "\n",
    "Hence, converting the emissions dataset to `.csv` ensures better accessibility and usability for analysis and presentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6fff071-b470-453f-bc36-f045e8beca74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV file saved to: /Users/nafis/Desktop/dataset_merge/Question 2/csiro_2019_to_2025.csv\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the .parquet file\n",
    "parquet_path = Path.home() / \"Desktop\" / \"dataset_merge\" / \"Question 2\" / \"csiro_2019_to_2025.parquet\"\n",
    "df = pl.read_parquet(parquet_path)\n",
    "\n",
    "# Define the output path for CSV\n",
    "output_path = Path.home() / \"Desktop\" / \"dataset_merge\" / \"Question 2\" / \"csiro_2019_to_2025.csv\"\n",
    "\n",
    "# Save as CSV\n",
    "df.write_csv(output_path)\n",
    "\n",
    "print(f\"‚úÖ CSV file saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82c5a22-3f72-4e3f-83cc-94665f6dc1b0",
   "metadata": {},
   "source": [
    "### ‚úÖ Validating Latest Available Timestamp in Dataset\n",
    "\n",
    "To confirm the most recent data point included in the dataset, the following command was used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9769ae2a-acb9-4655-b1c8-c17231c96c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 4, 30, 23, 55, tzinfo=zoneinfo.ZoneInfo(key='UTC'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['timestamp'].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50092696-2873-4566-846f-e6128da9b51b",
   "metadata": {},
   "source": [
    "This confirms that the most recent data point in the dataset is from April 30, 2025 at 23:55 UTC. This aligns with the intended data retrieval range (from 2019 to the latest available in 2025) and indicates:\n",
    "\n",
    "The CSIRO API successfully returned data up to the very end of April 2025.\n",
    "\n",
    "‚úÖ No missing trailing data from 2025, as might have been the case with earlier attempts.\n",
    "\n",
    "You are now working with the most complete and up-to-date emissions dataset available via the CSIRO platform for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a71af2-18fa-461e-bdb8-15164c1c5a23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
